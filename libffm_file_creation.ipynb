{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train, validation and test set for libffm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/scirpus/libffm-generator-lb-280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    \"\"\"Gini Evaluation metric\n",
    "\n",
    "    Score Gini for give True target and predicted target values\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "        y_true {np.array} -- True target values\n",
    "        y_prob {np.array} -- Predicted target values\n",
    "\n",
    "    Returns:\n",
    "        gini {float} -- calculated gini sccore\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "\n",
    "def stratify_split(df, target_col, split_size, cols_to_drop=None):\n",
    "    \"\"\"splits the data\n",
    "    \n",
    "    splits the data into the given ratio and drops the given columns in list\n",
    "    \n",
    "    Arguments:\n",
    "        df {pd.dataFrame} -- dataframe object to split\n",
    "        target_col {string} -- name if the target column\n",
    "        split_size {float} -- split size in range \n",
    "    \n",
    "    Keyword Arguments:\n",
    "        cols_to_drop {list} -- list of columns to drop (default: {None})\n",
    "    \"\"\"\n",
    "    \n",
    "    cols_to_drop = None if cols_to_drop is None else cols_to_drop\n",
    "    if cols_to_drop is not None:\n",
    "        df = df.drop(cols_to_drop, axis=1)\n",
    "        \n",
    "    X = df.loc[:, df.columns != target_col]\n",
    "    y = df[target_col]\n",
    "    \n",
    "\n",
    "    #sklearn stratify split\n",
    "    sss = StratifiedShuffleSplit(test_size=split_size, random_state=1001)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'porto_data/train.csv'\n",
    "TEST_PATH = 'porto_data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.insert(1,'target',0)\n",
    "x = pd.concat([train,test])\n",
    "x = x.reset_index(drop=True)\n",
    "unwanted = x.columns[x.columns.str.startswith('ps_calc_')]\n",
    "x.drop(unwanted,inplace=True,axis=1)\n",
    "\n",
    "\n",
    "features = x.columns[2:]\n",
    "categories = []\n",
    "for c in features:\n",
    "    trainno = len(x.loc[:train.shape[0],c].unique())\n",
    "    testno = len(x.loc[train.shape[0]:,c].unique())\n",
    "    print c,trainno,testno\n",
    "    \n",
    "    \n",
    "x.loc[:,'ps_reg_03'] = pd.cut(x['ps_reg_03'], 50,labels=False)\n",
    "x.loc[:,'ps_car_12'] = pd.cut(x['ps_car_12'], 50,labels=False)\n",
    "x.loc[:,'ps_car_13'] = pd.cut(x['ps_car_13'], 50,labels=False)\n",
    "x.loc[:,'ps_car_14'] =  pd.cut(x['ps_car_14'], 50,labels=False)\n",
    "x.loc[:,'ps_car_15'] =  pd.cut(x['ps_car_15'], 50,labels=False)\n",
    "\n",
    "\n",
    "\n",
    "test = x.loc[train.shape[0]:].copy()\n",
    "train = x.loc[:train.shape[0]].copy()\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val = stratify_split(train, 'target', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([y_train, X_train], axis=1)\n",
    "val = pd.concat([y_val, X_val], axis=1)\n",
    "\n",
    "train.drop('id',inplace=True,axis=1)\n",
    "val.drop('id',inplace=True,axis=1)\n",
    "test.drop('id',inplace=True,axis=1)\n",
    "\n",
    "categories = train.columns[1:]\n",
    "numerics = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentcode = len(numerics)\n",
    "catdict = {}\n",
    "catcodes = {}\n",
    "\n",
    "for x in numerics:\n",
    "    catdict[x] = 0\n",
    "for x in categories:\n",
    "    catdict[x] = 1\n",
    "\n",
    "#train\n",
    "noofrows = train.shape[0]\n",
    "noofcolumns = len(features)\n",
    "with open(\"alltrainffm_2.txt\", \"w\") as text_file:\n",
    "    for n, r in enumerate(range(noofrows)):\n",
    "        if((n%100000)==0):\n",
    "            print('Row',n)\n",
    "        datastring = \"\"\n",
    "        datarow = train.iloc[r].to_dict()\n",
    "        datastring += str(int(datarow['target']))\n",
    "\n",
    "\n",
    "        for i, x in enumerate(catdict.keys()):\n",
    "            if(catdict[x]==0):\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "            else:\n",
    "                if(x not in catcodes):\n",
    "                    catcodes[x] = {}\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "                elif(datarow[x] not in catcodes[x]):\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "\n",
    "                code = catcodes[x][datarow[x]]\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "        datastring += '\\n'\n",
    "        text_file.write(datastring)\n",
    "\n",
    "#val\n",
    "noofrows = val.shape[0]\n",
    "noofcolumns = len(features)\n",
    "with open(\"allvalffm_2.txt\", \"w\") as text_file:\n",
    "    for n, r in enumerate(range(noofrows)):\n",
    "        if((n%100000)==0):\n",
    "            print('Row',n)\n",
    "        datastring = \"\"\n",
    "        datarow = val.iloc[r].to_dict()\n",
    "        datastring += str(int(datarow['target']))\n",
    "\n",
    "\n",
    "        for i, x in enumerate(catdict.keys()):\n",
    "            if(catdict[x]==0):\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "            else:\n",
    "                if(x not in catcodes):\n",
    "                    catcodes[x] = {}\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "                elif(datarow[x] not in catcodes[x]):\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "\n",
    "                code = catcodes[x][datarow[x]]\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "        datastring += '\\n'\n",
    "        text_file.write(datastring)\n",
    "\n",
    "        \n",
    "#test\n",
    "noofrows = test.shape[0]\n",
    "noofcolumns = len(features)\n",
    "with open(\"alltestffm_2.txt\", \"w\") as text_file:\n",
    "    for n, r in enumerate(range(noofrows)):\n",
    "        if((n%100000)==0):\n",
    "            print('Row',n)\n",
    "        datastring = \"\"\n",
    "        datarow = test.iloc[r].to_dict()\n",
    "        datastring += str(int(datarow['target']))\n",
    "\n",
    "\n",
    "        for i, x in enumerate(catdict.keys()):\n",
    "            if(catdict[x]==0):\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "            else:\n",
    "                if(x not in catcodes):\n",
    "                    catcodes[x] = {}\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "                elif(datarow[x] not in catcodes[x]):\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "\n",
    "                code = catcodes[x][datarow[x]]\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "        datastring += '\\n'\n",
    "        text_file.write(datastring)\n",
    "        \n",
    "print \"DONE\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
