{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to implement stacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will demonstrate how to build a stacking structure. We will use sample porto_seguero data to build our two base models(XGB and LGB), and their Out Of Fold predictions to train Logistic Regressions(Our Stacker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load required Libraries\n",
    "#load important libraries\n",
    "#author:sohaib\n",
    "from __future__ import division\n",
    "#import required modules\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# to supress printing of exponential notation in pandas\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download the porto data from : https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data\n",
    "TRAIN_PATH = 'porto_data/train.csv'\n",
    "TEST_PATH = 'porto_data/test.csv'\n",
    "THREADS=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    \"\"\"Gini Evaluation metric\n",
    "\n",
    "    Score Gini for give True target and predicted target values\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "        y_true {np.array} -- True target values\n",
    "        y_prob {np.array} -- Predicted target values\n",
    "\n",
    "    Returns:\n",
    "        gini {float} -- calculated gini sccore\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "\n",
    "def auc_to_gini(score):\n",
    "    \"\"\"Converts AUC to Gini\n",
    "       \n",
    "    Arguments:\n",
    "        score {float} -- AUC score\n",
    "    \n",
    "    Returns:\n",
    "        [float] -- gini score\n",
    "    \"\"\"\n",
    "    \n",
    "    gini = (2 * score) - 1\n",
    "    return gini\n",
    "\n",
    "\n",
    "def bold(text_to_bold):\n",
    "    \"\"\"Bolds the given string\n",
    "       \n",
    "    Arguments:\n",
    "        text_to_bold {string} -- string to bold\n",
    "\n",
    "    Returns:\n",
    "        [string]: Bold string\n",
    "    \"\"\"\n",
    "    \n",
    "    bold = \"\\033[1m\"\n",
    "    reset = \"\\033[0;0m\"\n",
    "    bold_text = bold + text_to_bold + reset \n",
    "    \n",
    "    return bold_text\n",
    "\n",
    "#__author__ = harishasan\n",
    "def timer(start_time=None):\n",
    "    \"\"\"Prints time\n",
    "    \n",
    "    Initiate a time object, and prints total time consumed when again initialized object is passed as argument\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        start_time {[object]} -- initialized time object (default: {None})\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "       \n",
    "\n",
    "    \n",
    "def calculate_avg(scores):\n",
    "    \"\"\"calculates average of given allay or list\n",
    "    \n",
    "    Arguments:\n",
    "        scores {[np.array]} -- array of scores\n",
    "    \"\"\"\n",
    "    avg = sum(scores)/ float(len(scores))\n",
    "    return avg\n",
    "\n",
    "def stacker(stacker_model, s_train, target, s_test):\n",
    "    \"\"\"trains stacker model on base models predictions and test on base model test predictions dataset\n",
    "       \n",
    "    Arguments:\n",
    "        stacker_model {[type]} -- model to traina s stacker\n",
    "        s_train {[type]} -- stacker train set\n",
    "        target {[type]} -- target(y) for model\n",
    "        s_test {[type]} -- stacker test set\n",
    "    \n",
    "    Returns:\n",
    "        [pd.DataFrame] -- predictions dataframem\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = timer(None)\n",
    "    stacker_model.fit(s_train, target)\n",
    "    preds = stacker_model.predict_proba(s_test)[:, 1]\n",
    "    timer(start_time)\n",
    "    preds_df = pd.DataFrame(data=preds, columns=['target']) \n",
    "    \n",
    "    return preds_df\n",
    "\n",
    "\n",
    "\n",
    "def get_base_model_results(model, X, y, test, model_name='base_model', y_test=None, n_splits=5, random_state=0, save_fold_results=True, fold_results_path='base_models_results/'):\n",
    "    \"\"\"for given model produces OOF and test predictions\n",
    "    \n",
    "    For the given Number of Folds, trains the model on train set, predicts on Out OF FOld set and test set, and repeat for given number of Folds.\n",
    "    \n",
    "    Arguments:\n",
    "        model {Object} -- Model i.e XGB, LGB...\n",
    "        X {nd.array} -- Train set\n",
    "        y {np.array} -- target values of train set\n",
    "        test {nd.array} -- test set\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        y_test {np.array} -- test set target values (default: {None})\n",
    "        n_splits {int} -- Number of folds for Cross Validation split (default: {5})\n",
    "        random_state {int} -- random seed to use in making folds for Cross Validation (default: {0})\n",
    "        save_fold_results {bool} -- save out of fold predections and test or Not (default: True)\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "        tuple -- tuple of Dataframe of Out Of Fold and test set Predictions\n",
    "    \"\"\"\n",
    "    #TODO: refactor this function in to small reusable chunks.\n",
    "    \n",
    "    print bold(\"STARTING ITERATION FOR\") + \" \" + bold(model_name)\n",
    "    \n",
    "    train_preds_auc = []\n",
    "    train_preds_gini = []\n",
    "    \n",
    "    holdout_preds_auc = []\n",
    "    holdout_preds_gini = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state).split(X, y))\n",
    "    \n",
    "    stacker_train = np.zeros(X.shape[0])\n",
    "    stacker_foldtest = np.zeros((test.shape[0], n_splits))\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(folds):\n",
    "        print \"Fold {}\".format(str(i))\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_holdout = X[test_idx]\n",
    "        y_holdout = y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        preds_train = model.predict_proba(X_train)[:, 1] \n",
    "        preds = model.predict_proba(X_holdout)[:, 1]\n",
    "        \n",
    "        train_gini = eval_gini(y_train, preds_train)\n",
    "        \n",
    "        holdout_gini = eval_gini(y_holdout, preds)\n",
    "        \n",
    "        \n",
    "        print \"Training gini = {}    Holdout gini = {}\\n\".format(str(train_gini), str(holdout_gini))\n",
    "        \n",
    "\n",
    "#         print \"making stacker train\"\n",
    "        stacker_train[test_idx] = preds\n",
    "        \n",
    "        stacker_foldtest[:, i] = model.predict_proba(test)[:, 1]\n",
    "        \n",
    "        #append fold results to list\n",
    "        train_preds_gini.append(train_gini)\n",
    "        \n",
    "        holdout_preds_gini.append(holdout_gini)\n",
    "    \n",
    "    \n",
    "    foldtest_mean = stacker_foldtest.mean(axis=1)\n",
    "    stacker_test = foldtest_mean\n",
    "    print \"\\nAverage gini of training = {}    Average gini of holdouts = {} \\n\".format(str(calculate_avg(train_preds_gini)), str(calculate_avg(holdout_preds_gini)))\n",
    "    \n",
    "    print \"Folds variance for train {:.3f}    Folds variance for holdouts = {:.3f}\\n\".format(np.std(train_preds_gini), np.std(holdout_preds_gini))\n",
    "    if y_test is not None:\n",
    "        print bold(\"Test GINI = \") + \" {:.5f}\".format(auc_to_gini(roc_auc_score(y_test, stacker_test)))\n",
    "    print \"\\nTraining time in Minutes {} \\n \\n\".format(str((time.time() - start_time)/60))   \n",
    "\n",
    "    oof_preds = pd.DataFrame(data=stacker_train, columns=['{}train'.format(model_name)])\n",
    "    test_preds = pd.DataFrame(data=stacker_test, columns=['{}test'.format(model_name)])\n",
    "    \n",
    "    if save_fold_results:\n",
    "        oof_preds.to_csv(fold_results_path + 'oof_{}.csv'.format(model_name), index=False)\n",
    "        test_preds.to_csv(fold_results_path + 'test_{}.csv'.format(model_name), index=False)\n",
    "    \n",
    "    return (oof_preds, test_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the train and test data\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "\n",
    "id_test = test['id'].values\n",
    "id_train = train['id'].values\n",
    "y = train['target']\n",
    "\n",
    "### Drop calc\n",
    "unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "train.drop(unwanted, axis=1, inplace=True)  \n",
    "test.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "train.drop(['id', 'target'], axis=1, inplace=True)\n",
    "test.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define base models and stacker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here we use two base models XGB and LGB\n",
    "xgb_base = XGBClassifier(nthread=THREADS)\n",
    "lgb_base = LGBMClassifier(num_threads=THREADS)\n",
    "\n",
    "#stacker Model\n",
    "lr_stacker = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSTARTING ITERATION FOR\u001b[0;0m \u001b[1mxgb_base\u001b[0;0m\n",
      "Fold 0\n",
      "Training gini = 0.340645764921    Holdout gini = 0.275406236435\n",
      "\n",
      "Fold 1\n",
      "Training gini = 0.33851851826    Holdout gini = 0.259669414449\n",
      "\n",
      "Fold 2\n",
      "Training gini = 0.340736587994    Holdout gini = 0.241749774065\n",
      "\n",
      "Fold 3\n",
      "Training gini = 0.340662367258    Holdout gini = 0.261198984291\n",
      "\n",
      "Fold 4\n",
      "Training gini = 0.346551848993    Holdout gini = 0.235377882626\n",
      "\n",
      "\n",
      "Average gini of training = 0.341423017485    Average gini of holdouts = 0.254680458373 \n",
      "\n",
      "Folds variance for train 0.003    Folds variance for holdouts = 0.014\n",
      "\n",
      "\n",
      "Training time in Minutes 0.260008366903 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gets oof and test predictions for the stacker\n",
    "#first for XGB\n",
    "xgb_oof_pred, xgb_test_pred = get_base_model_results(xgb_base, train, y, test, model_name='xgb_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSTARTING ITERATION FOR\u001b[0;0m \u001b[1mlgb_base\u001b[0;0m\n",
      "Fold 0\n",
      "Training gini = 0.260276217994    Holdout gini = 0.23153844655\n",
      "\n",
      "Fold 1\n",
      "Training gini = 0.255141807083    Holdout gini = 0.199481760163\n",
      "\n",
      "Fold 2\n",
      "Training gini = 0.269546061365    Holdout gini = 0.206483090163\n",
      "\n",
      "Fold 3\n",
      "Training gini = 0.259199540103    Holdout gini = 0.220051355943\n",
      "\n",
      "Fold 4\n",
      "Training gini = 0.268139743917    Holdout gini = 0.208116253322\n",
      "\n",
      "\n",
      "Average gini of training = 0.262460674092    Average gini of holdouts = 0.213134181228 \n",
      "\n",
      "Folds variance for train 0.006    Folds variance for holdouts = 0.011\n",
      "\n",
      "\n",
      "Training time in Minutes 0.0246824502945 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_oof_pred, lgb_test_pred = get_base_model_results(lgb_base, train, y, test,  model_name='lgb_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make stacker train and test df\n",
    "stacker_train = pd.concat([xgb_oof_pred, lgb_oof_pred], axis=1)\n",
    "stacker_test = pd.concat([xgb_test_pred, lgb_test_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCV of stacker:\u001b[0;0m 0.2539\n"
     ]
    }
   ],
   "source": [
    "#check cross val score of stacker\n",
    "results = cross_val_score(lr_stacker, stacker_train, y=y, cv=5, scoring='roc_auc')\n",
    "print bold('CV of stacker:') + ' {:.4f}'.format(auc_to_gini(results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 0 minutes and 0.21 seconds.\n"
     ]
    }
   ],
   "source": [
    "#now train stacker on all OOF predictions and test\n",
    "test_stacker_preds = stacker(lr_stacker, stacker_train, y, stacker_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
